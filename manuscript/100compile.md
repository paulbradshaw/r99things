# Section 1: Compile

Data journalism begins in one of two ways: either you have a question that needs data, or a dataset that needs questioning. Whichever it is, the compilation of data is what defines it as an act of data journalism.

Compiling data can take various forms. At its most simple the data might be:

* Supplied directly to you by an organisation (how long until we see ‘data releases’ alongside press releases?),
* Found through using advanced search techniques to plough into the depths of government websites;
* Compiled by scraping databases hidden behind online forms or pages of results using tools like OutWit Hub and Scraperwiki;
* By converting documents into something that can be analysed, using tools like DocumentCloud;
* By pulling information from APIs;
* Or by collecting the data yourself through observation, surveys, online forms or crowdsourcing.

This compilation stage is the most important – not only because everything else rests on that, but because it is probably the stage that is returned to the most – at each of the subsequent stages – cleaning, contextualising, combining and communicating – it may be that you need to compile further information.
